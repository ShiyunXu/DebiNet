{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "DPLM_Figure3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "I_uVV9gkVoUK",
        "outputId": "5a1ad2c2-ee3d-4291-e1ca-7ee19180177e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
        "from sklearn.preprocessing import *\n",
        "from sklearn.linear_model import *\n",
        "from sklearn.model_selection import train_test_split\n",
        "from matplotlib import pyplot as plt\n",
        "import time\n",
        "from sklearn.metrics import mean_squared_error as MSE\n",
        "import statsmodels.api as sm\n",
        "import scipy\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.feature_extraction import DictVectorizer\n",
        "from sklearn.preprocessing import *\n",
        "import copy\n",
        "from sklearn.metrics import *\n",
        "import os\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aQZ2z_BoRl7n",
        "colab_type": "text"
      },
      "source": [
        "# 7.1 Treatment effect\n",
        "\n",
        "(all that can do inference) PLMNN, DML(Lasso),DML(RF),PLM NW(vanilla),OLS,pure NN\n",
        "\n",
        "test MSE, train MSE, betahat,betahat SD"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6dyGNyxYRtHI",
        "colab_type": "text"
      },
      "source": [
        "## Data preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1drh7LM4qQNx",
        "colab_type": "code",
        "outputId": "9a05ac40-27c3-4955-c00a-f02c38b17733",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fE9c5cOYRr3G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = pd.read_stata('/content/drive/My Drive/DPLM/sipp1991.dta')\n",
        "Variables = [\"inc\", 'e401', \"age\", \"educ\", \"fsize\", \"marr\", \"twoearn\", \"db\", \"pira\", \"hown\"]\n",
        "# Variables = ['e401', \"age\", \"inc\", \"educ\", \"fsize\", \"marr\", \"twoearn\", \"db\", \"pira\", \"hown\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WBFP3uNW_f0P",
        "colab_type": "code",
        "outputId": "a9f8adff-138e-426a-fcc9-7dba10b83626",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "data.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>nifa</th>\n",
              "      <th>net_tfa</th>\n",
              "      <th>tw</th>\n",
              "      <th>age</th>\n",
              "      <th>inc</th>\n",
              "      <th>fsize</th>\n",
              "      <th>educ</th>\n",
              "      <th>db</th>\n",
              "      <th>marr</th>\n",
              "      <th>twoearn</th>\n",
              "      <th>e401</th>\n",
              "      <th>p401</th>\n",
              "      <th>pira</th>\n",
              "      <th>hown</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4500.0</td>\n",
              "      <td>47</td>\n",
              "      <td>6765.0</td>\n",
              "      <td>2</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>6215.0</td>\n",
              "      <td>1015.0</td>\n",
              "      <td>22390.0</td>\n",
              "      <td>36</td>\n",
              "      <td>28452.0</td>\n",
              "      <td>1</td>\n",
              "      <td>16</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>-2000.0</td>\n",
              "      <td>-2000.0</td>\n",
              "      <td>37</td>\n",
              "      <td>3300.0</td>\n",
              "      <td>6</td>\n",
              "      <td>12</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>15000.0</td>\n",
              "      <td>15000.0</td>\n",
              "      <td>155000.0</td>\n",
              "      <td>58</td>\n",
              "      <td>52590.0</td>\n",
              "      <td>2</td>\n",
              "      <td>16</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>58000.0</td>\n",
              "      <td>32</td>\n",
              "      <td>21804.0</td>\n",
              "      <td>1</td>\n",
              "      <td>11</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      nifa  net_tfa        tw  age      inc  ...  twoearn  e401  p401  pira  hown\n",
              "0      0.0      0.0    4500.0   47   6765.0  ...        0     0     0     0     1\n",
              "1   6215.0   1015.0   22390.0   36  28452.0  ...        0     0     0     0     1\n",
              "2      0.0  -2000.0   -2000.0   37   3300.0  ...        0     0     0     0     0\n",
              "3  15000.0  15000.0  155000.0   58  52590.0  ...        1     0     0     0     1\n",
              "4      0.0      0.0   58000.0   32  21804.0  ...        0     0     0     0     1\n",
              "\n",
              "[5 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fk2kE5SKgYSy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y = data.net_tfa.values.reshape(-1, 1)\n",
        "tempp = data[Variables]\n",
        "X = tempp.values\n",
        "ymax=np.max(y);ymin=np.min(y)\n",
        "# factor=1e4;y=y/factor\n",
        "# y = MinMaxScaler().fit_transform(y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "om9Aarojrywq",
        "colab_type": "code",
        "outputId": "ab90ece9-17ea-4bc6-d884-6b85bd0269a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9915, 10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_0nWYAGuXXVr",
        "colab_type": "text"
      },
      "source": [
        "## PLMNN, NW, Lasso, Regression tree, Random forest"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_pULwzcw0uGT",
        "colab_type": "text"
      },
      "source": [
        "### models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E6HJpsXYXmR_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"The :mod:`sklearn.kernel_regressor` module implements the Kernel Regressor.\n",
        "\"\"\"\n",
        "# Author: Jan Hendrik Metzen <janmetzen@mailbox.de>\n",
        "#\n",
        "# License: BSD 3 clause\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.metrics.pairwise import pairwise_kernels\n",
        "from sklearn.base import BaseEstimator, RegressorMixin\n",
        "\n",
        "\n",
        "class KernelRegression(BaseEstimator, RegressorMixin):\n",
        "    \"\"\"Nadaraya-Watson kernel regression with automatic bandwidth selection.\n",
        "\n",
        "    This implements Nadaraya-Watson kernel regression with (optional) automatic\n",
        "    bandwith selection of the kernel via leave-one-out cross-validation. Kernel\n",
        "    regression is a simple non-parametric kernelized technique for learning\n",
        "    a non-linear relationship between input variable(s) and a target variable.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    kernel : string or callable, default=\"rbf\"\n",
        "        Kernel map to be approximated. A callable should accept two arguments\n",
        "        and the keyword arguments passed to this object as kernel_params, and\n",
        "        should return a floating point number.\n",
        "\n",
        "    gamma : float, default=None\n",
        "        Gamma parameter for the RBF (\"bandwidth\"), polynomial,\n",
        "        exponential chi2 and sigmoid kernels. Interpretation of the default\n",
        "        value is left to the kernel; see the documentation for\n",
        "        sklearn.metrics.pairwise. Ignored by other kernels. If a sequence of\n",
        "        values is given, one of these values is selected which minimizes\n",
        "        the mean-squared-error of leave-one-out cross-validation.\n",
        "\n",
        "    See also\n",
        "    --------\n",
        "\n",
        "    sklearn.metrics.pairwise.kernel_metrics : List of built-in kernels.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, kernel=\"rbf\", gamma=None):\n",
        "        self.kernel = kernel\n",
        "        self.gamma = gamma\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        \"\"\"Fit the model\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : array-like of shape = [n_samples, n_features]\n",
        "            The training input samples.\n",
        "\n",
        "        y : array-like, shape = [n_samples, m]\n",
        "            The target values\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        self : object\n",
        "            Returns self.\n",
        "        \"\"\"\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "\n",
        "        if hasattr(self.gamma, \"__iter__\"):\n",
        "            self.gamma = self._optimize_gamma(self.gamma)\n",
        "\n",
        "        return self\n",
        "\n",
        "    def predict(self, X_test):\n",
        "        \"\"\"Predict target values for X_test, size m*n_features.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        X_test : array-like of shape = [n_te_samples, n_features]\n",
        "            The input samples.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        y : array of shape = [n_te_samples, m]\n",
        "            The predicted target value.\n",
        "        \"\"\"\n",
        "        K = pairwise_kernels(self.X, X_test, metric=self.kernel, gamma=self.gamma)\n",
        "        # K.shape=[n_tr_samples, n_te_samples]\n",
        "        # self.X.shape=[n_tr_samples, n_features]\n",
        "        # self.y.shape=[n_tr_samples, m]\n",
        "        if self.y.ndim==1:\n",
        "            ncol=1\n",
        "        else:\n",
        "            ncol=self.y.shape[1]\n",
        "        numerator=(np.transpose(self.y).dot(K)).reshape(ncol,K.shape[1])\n",
        "        return np.transpose(numerator / K.sum(axis=0))\n",
        "\n",
        "    def _optimize_gamma(self, gamma_values):\n",
        "        # Select specific value of gamma from the range of given gamma_values\n",
        "        # by minimizing mean-squared error in leave-one-out cross validation\n",
        "        mse = np.empty_like(gamma_values, dtype=np.float)\n",
        "        for i, gamma in enumerate(gamma_values):\n",
        "            K = pairwise_kernels(self.X, self.X, metric=self.kernel,\n",
        "                                 gamma=gamma)\n",
        "            np.fill_diagonal(K, 0)  # leave-one-out\n",
        "            Ky = K * self.y[:, np.newaxis]\n",
        "            y_pred = Ky.sum(axis=0) / K.sum(axis=0)\n",
        "            mse[i] = ((y_pred - self.y) ** 2).mean()\n",
        "\n",
        "        return gamma_values[np.nanargmin(mse)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eNcKKbi6G7T-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def newset(y, Z, T):\n",
        "  new_y = torch.tensor(np.concatenate((y, Z), axis=1)).float()\n",
        "  new_data = torch.tensor(T).float()\n",
        "  return new_y, new_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UGsNO19SvEfR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def PLMNN(y_train, Z_train, T_train, y_test, Z_test, T_test):\n",
        "\n",
        "  D_in, H, D_out = T_train.shape[1], 10000, Z_train.shape[1]+1\n",
        "  max_epoch, lr, batch_size = 20, 1e-5, 256\n",
        "\n",
        "  yZ_train, T_train = newset(y_train, Z_train, T_train)\n",
        "  yZ_test, T_test = newset(y_test, Z_test, T_test)\n",
        "\n",
        "  new_T_train, new_T_val, new_yZ_train, new_yZ_val = \\\n",
        "  train_test_split(T_train, yZ_train, test_size=0.2, random_state=42)\n",
        "\n",
        "  Train_dataset = TensorDataset(new_T_train, new_yZ_train)\n",
        "  trainloader = DataLoader(dataset=Train_dataset, batch_size=batch_size, shuffle=True)\n",
        "  Test_dataset = TensorDataset(new_T_val, new_yZ_val)\n",
        "  testloader = DataLoader(dataset=Test_dataset, batch_size=1, shuffle=False)\n",
        "\n",
        "\n",
        "  model = nn.Sequential(\n",
        "    nn.Linear(D_in, H),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(H, D_out),\n",
        ")\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr=lr,weight_decay=2)\n",
        "  criterion = nn.MSELoss()\n",
        "  old_val_error=1e12\n",
        "  patience=0\n",
        "\n",
        "  for epoch in range(max_epoch):\n",
        "    for batch_T, batch_yZ in trainloader:\n",
        "      optimizer.zero_grad()\n",
        "      batch_yZ_pred = model(batch_T)\n",
        "      batch_loss = criterion(batch_yZ_pred, batch_yZ)\n",
        "      batch_loss.backward()\n",
        "      optimizer.step()\n",
        "    with torch.no_grad():\n",
        "      yZ_pred = model(new_T_val)\n",
        "      val_loss = criterion(yZ_pred, new_yZ_val)\n",
        "      # print(epoch, val_loss)\n",
        "\n",
        "    #early stopping\n",
        "    if val_loss.item()<old_val_error:\n",
        "      old_val_error=val_loss.item()\n",
        "      patience=0\n",
        "    else:\n",
        "      patience+=1\n",
        "    if patience == 1:\n",
        "      print('break at epoch:', epoch)\n",
        "      break\n",
        "    \n",
        "  model.eval()\n",
        "  ml_pred_ytrain, ml_pred_Ztrain = \\\n",
        "  model(T_train)[:, 0].detach().numpy(), model(T_train)[:, 1:].detach().numpy()\n",
        "  ml_pred_ytest, ml_pred_Ztest = \\\n",
        "  model(T_test)[:, 0].detach().numpy(), model(T_test)[:, 1:].detach().numpy()\n",
        "  return ml_pred_ytrain.reshape(-1,1), ml_pred_Ztrain, ml_pred_ytest.reshape(-1,1), ml_pred_Ztest"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kE159-ak0zEG",
        "colab_type": "text"
      },
      "source": [
        "### Partial out"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yl3iteFaJfNt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def PatialOut(y_train, Z_train, T_train, y_test, Z_test, T_test, ml):\n",
        "  if ml == 'PLMNN':\n",
        "    ml_pred_ytrain, ml_pred_Ztrain, ml_pred_ytest, ml_pred_Ztest = \\\n",
        "    PLMNN(y_train, Z_train, T_train, y_test, Z_test, T_test)\n",
        "\n",
        "  else: \n",
        "    if ml == 'Kernel':\n",
        "      ml_y = KernelRegression() \n",
        "      ml_Z = KernelRegression() \n",
        "\n",
        "    elif ml == 'Lasso':\n",
        "      ml_y = Lasso(alpha = 1, max_iter=1e4) \n",
        "      ml_Z = Lasso(alpha = 1, max_iter=1e4) \n",
        "\n",
        "    elif ml == 'Regression tree':\n",
        "      ml_y = DecisionTreeRegressor(max_depth=2)\n",
        "      ml_Z = DecisionTreeRegressor(max_depth=2) \n",
        "\n",
        "    elif ml == 'Random forest':\n",
        "      ml_y = RandomForestRegressor(max_depth=2)\n",
        "      ml_Z = RandomForestRegressor(max_depth=2) \n",
        "\n",
        "    else:\n",
        "      print('Wrong ML name!')\n",
        "\n",
        "    ml_y.fit(T_train, y_train)\n",
        "    ml_Z.fit(T_train, Z_train)\n",
        "    ml_pred_ytrain = ml_y.predict(T_train).reshape(-1,1)\n",
        "    ml_pred_ytest = ml_y.predict(T_test).reshape(-1,1)\n",
        "    # print(ml_pred_ytest)\n",
        "    ml_pred_Ztrain = ml_Z.predict(T_train).reshape(-1,1)\n",
        "    ml_pred_Ztest = ml_Z.predict(T_test).reshape(-1,1)\n",
        "\n",
        "    ### remove nan rows for kernel regression\n",
        "    na_index=np.isnan(ml_pred_ytest*ml_pred_Ztest)\n",
        "    y_test = y_test[~na_index].reshape(-1,1)\n",
        "    ml_pred_ytest = ml_pred_ytest[~na_index].reshape(-1,1)\n",
        "    Z_test = Z_test[~na_index].reshape(-1,1)\n",
        "    ml_pred_Ztest = ml_pred_Ztest[~na_index].reshape(-1,1)\n",
        "\n",
        "  # OLS\n",
        "  ols_train = LinearRegression(fit_intercept=False).\\\n",
        "  fit(Z_train-ml_pred_Ztrain, y_train-ml_pred_ytrain)\n",
        "  # beta = ols_train.coef_\n",
        "  ytrain_pred = ols_train.predict(Z_train-ml_pred_Ztrain) + ml_pred_ytrain\n",
        "  ytrain_mse = np.mean((ytrain_pred-y_train)**2) \n",
        "  # print(ml, Z_test.shape, ml_pred_Ztest.shape, y_test.shape, ml_pred_ytest.shape)\n",
        "\n",
        "  ols_test = LinearRegression(fit_intercept=False).\\\n",
        "  fit(Z_test-ml_pred_Ztest, y_test-ml_pred_ytest)\n",
        "  beta = ols_test.coef_\n",
        "  ytest_pred = ols_test.predict(Z_test-ml_pred_Ztest) + ml_pred_ytest\n",
        "  ytest_mse = np.mean((ytest_pred-y_test)**2)\n",
        "  # print(ytrain_mse.shape, beta.shape)\n",
        "  return ytrain_mse, ytest_mse, beta"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TSxwpNgi03jF",
        "colab_type": "text"
      },
      "source": [
        "### Run"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g0SKb6T5Ldm3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "kfold = 10\n",
        "torch.manual_seed(1)\n",
        "kf = KFold(n_splits=kfold)\n",
        "count = 0\n",
        "ytrain_mse_plm, ytest_mse_plm, beta_plm = np.zeros(kfold), np.zeros(kfold), np.zeros(kfold)\n",
        "ytrain_mse_nw, ytest_mse_nw, beta_nw = np.zeros(kfold), np.zeros(kfold), np.zeros(kfold)\n",
        "ytrain_mse_lasso, ytest_mse_lasso, beta_lasso = np.zeros(kfold), np.zeros(kfold), np.zeros(kfold)\n",
        "ytrain_mse_rt, ytest_mse_rt, beta_rt = np.zeros(kfold), np.zeros(kfold), np.zeros(kfold)\n",
        "ytrain_mse_rf, ytest_mse_rf, beta_rf = np.zeros(kfold), np.zeros(kfold), np.zeros(kfold)\n",
        "beta_ols=np.zeros(kfold)\n",
        "\n",
        "for train_index, test_index in kf.split(X):\n",
        "  X_train, X_test = X[train_index], X[test_index]\n",
        "  y_train, y_test = y[train_index], y[test_index]\n",
        "  Z_train, T_train = X_train[:, 0].reshape((-1,1)), X_train[:, 1:]\n",
        "  Z_test, T_test = X_test[:, 0].reshape((-1,1)),  X_test[:, 1:]\n",
        "  \n",
        "  # OLS\n",
        "\n",
        "  # PLMNN\n",
        "  ytrain_mse_plm[count], ytest_mse_plm[count], beta_plm[count] = \\\n",
        "  PatialOut(y_train, Z_train, T_train, y_test, Z_test, T_test, ml='PLMNN')\n",
        "\n",
        "  # Kernel regression\n",
        "  ytrain_mse_nw[count], ytest_mse_nw[count], beta_nw[count] = \\\n",
        "  PatialOut(y_train, Z_train, T_train, y_test, Z_test, T_test, ml='Kernel')\n",
        "\n",
        "  # Lasso\n",
        "  ytrain_mse_lasso[count], ytest_mse_lasso[count], beta_lasso[count] = \\\n",
        "  PatialOut(y_train, Z_train, T_train, y_test, Z_test, T_test, ml='Lasso')\n",
        "\n",
        "\n",
        "  # Regression tree\n",
        "  ytrain_mse_rt[count], ytest_mse_rt[count], beta_rt[count] = \\\n",
        "  PatialOut(y_train, Z_train, T_train, y_test, Z_test, T_test, ml='Regression tree')\n",
        "\n",
        "  # Random forest\n",
        "  ytrain_mse_rf[count], ytest_mse_rf[count], beta_rf[count] = \\\n",
        "  PatialOut(y_train, Z_train, T_train, y_test, Z_test, T_test, ml='Random forest')\n",
        "  \n",
        "  count += 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1QGOxgiQ07xr",
        "colab_type": "text"
      },
      "source": [
        "### Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hkKyHPhx0pB-",
        "colab_type": "code",
        "outputId": "3d3c065e-aecb-46ef-cdff-fc131535e5c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(np.mean(beta_plm),np.median(beta_plm), np.std(beta_plm))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.5908993929624557 0.5969221889972687 0.18650778460626732\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gQmSKlfnNrQY",
        "colab_type": "code",
        "outputId": "94f3b5d1-ce48-4079-df9c-5bfa6c2b1c7a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(np.mean(beta_nw),np.median(beta_nw), np.std(beta_nw))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9121383309364319 0.9318813383579254 0.3513529386816794\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FpRZbtJ-TXAV",
        "colab_type": "code",
        "outputId": "68bda966-01fd-4bb6-d329-04600703d1c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(np.mean(beta_lasso),np.median(beta_lasso), np.std(beta_lasso))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8879226535558701 0.9111838936805725 0.41592935033775524\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SUu8EwvbXEla",
        "colab_type": "code",
        "outputId": "f5f90ac3-895e-4198-acbf-c8bd681e480f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(np.mean(beta_rt),np.median(beta_rt), np.std(beta_rt))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.805973433378685 0.8041305485237005 0.38551140281672236\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "60WtljQ9XFOC",
        "colab_type": "code",
        "outputId": "fb74e7ef-de44-4a95-8803-5e3b79da02dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(np.mean(beta_rf),np.median(beta_rf), np.std(beta_rf))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8099061044261481 0.8103805138120654 0.38879054020987985\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I5jn5faT1maU",
        "colab_type": "code",
        "outputId": "62577705-eac3-4e42-f4aa-5c7ace2e3d3f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        }
      },
      "source": [
        "plt.boxplot([beta_plm,beta_nw,beta_lasso,beta_rt,beta_rf])\n",
        "plt.xticks(range(1,6),['PLMNN','PLMNW','DML Lasso','DML DT','DML RF'],fontsize=12)\n",
        "plt.ylabel(r'$\\hat\\beta$',fontsize=16)\n",
        "plt.savefig('treatment.pdf');plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YtKRuGhFRhr5",
        "colab_type": "text"
      },
      "source": [
        "# 7.2 Adversarial attack"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ux0x2vT1qa9l",
        "colab_type": "text"
      },
      "source": [
        "## Data preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pmzGIkAjqggt",
        "colab_type": "code",
        "outputId": "ca855908-f758-4393-c35f-74111e073dec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "import pandas as pd\n",
        "# df = pd.read_csv('/content/drive/My Drive/DPLM/German_credit.csv')\n",
        "# df = pd.read_csv('/content/drive/My Drive/DPLM/UCI_Credit_Card.csv')\n",
        "df = pd.read_csv('/content/drive/My Drive/DPLM/UCI_Credit_Card 2.csv')\n",
        "df.keys()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['ID', 'LIMIT_BAL', 'SEX', 'EDUCATION', 'MARRIAGE', 'AGE', 'PAY_0',\n",
              "       'PAY_2', 'PAY_3', 'PAY_4', 'PAY_5', 'PAY_6', 'BILL_AMT1', 'BILL_AMT2',\n",
              "       'BILL_AMT3', 'BILL_AMT4', 'BILL_AMT5', 'BILL_AMT6', 'PAY_AMT1',\n",
              "       'PAY_AMT2', 'PAY_AMT3', 'PAY_AMT4', 'PAY_AMT5', 'PAY_AMT6',\n",
              "       'default.payment.next.month'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pj8V0ih2mgOV",
        "colab_type": "code",
        "outputId": "abe4186a-02b8-4137-9259-91a220581ef0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        }
      },
      "source": [
        "df=df.rename(columns = {'default.payment.next.month':'default'})\n",
        "print(df.shape)\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(30000, 25)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>LIMIT_BAL</th>\n",
              "      <th>SEX</th>\n",
              "      <th>EDUCATION</th>\n",
              "      <th>MARRIAGE</th>\n",
              "      <th>AGE</th>\n",
              "      <th>PAY_0</th>\n",
              "      <th>PAY_2</th>\n",
              "      <th>PAY_3</th>\n",
              "      <th>PAY_4</th>\n",
              "      <th>PAY_5</th>\n",
              "      <th>PAY_6</th>\n",
              "      <th>BILL_AMT1</th>\n",
              "      <th>BILL_AMT2</th>\n",
              "      <th>BILL_AMT3</th>\n",
              "      <th>BILL_AMT4</th>\n",
              "      <th>BILL_AMT5</th>\n",
              "      <th>BILL_AMT6</th>\n",
              "      <th>PAY_AMT1</th>\n",
              "      <th>PAY_AMT2</th>\n",
              "      <th>PAY_AMT3</th>\n",
              "      <th>PAY_AMT4</th>\n",
              "      <th>PAY_AMT5</th>\n",
              "      <th>PAY_AMT6</th>\n",
              "      <th>default</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>20000.0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>24</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-2</td>\n",
              "      <td>-2</td>\n",
              "      <td>3913.0</td>\n",
              "      <td>3102.0</td>\n",
              "      <td>689.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>689.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>120000.0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>26</td>\n",
              "      <td>-1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2682.0</td>\n",
              "      <td>1725.0</td>\n",
              "      <td>2682.0</td>\n",
              "      <td>3272.0</td>\n",
              "      <td>3455.0</td>\n",
              "      <td>3261.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2000.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>90000.0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>34</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>29239.0</td>\n",
              "      <td>14027.0</td>\n",
              "      <td>13559.0</td>\n",
              "      <td>14331.0</td>\n",
              "      <td>14948.0</td>\n",
              "      <td>15549.0</td>\n",
              "      <td>1518.0</td>\n",
              "      <td>1500.0</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>5000.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>50000.0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>37</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>46990.0</td>\n",
              "      <td>48233.0</td>\n",
              "      <td>49291.0</td>\n",
              "      <td>28314.0</td>\n",
              "      <td>28959.0</td>\n",
              "      <td>29547.0</td>\n",
              "      <td>2000.0</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>1200.0</td>\n",
              "      <td>1100.0</td>\n",
              "      <td>1069.0</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>50000.0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>57</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8617.0</td>\n",
              "      <td>5670.0</td>\n",
              "      <td>35835.0</td>\n",
              "      <td>20940.0</td>\n",
              "      <td>19146.0</td>\n",
              "      <td>19131.0</td>\n",
              "      <td>2000.0</td>\n",
              "      <td>36681.0</td>\n",
              "      <td>10000.0</td>\n",
              "      <td>9000.0</td>\n",
              "      <td>689.0</td>\n",
              "      <td>679.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   ID  LIMIT_BAL  SEX  EDUCATION  ...  PAY_AMT4  PAY_AMT5  PAY_AMT6  default\n",
              "0   1    20000.0    2          2  ...       0.0       0.0       0.0        1\n",
              "1   2   120000.0    2          2  ...    1000.0       0.0    2000.0        1\n",
              "2   3    90000.0    2          2  ...    1000.0    1000.0    5000.0        0\n",
              "3   4    50000.0    2          2  ...    1100.0    1069.0    1000.0        0\n",
              "4   5    50000.0    1          2  ...    9000.0     689.0     679.0        0\n",
              "\n",
              "[5 rows x 25 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3SQvWx9t7Mvi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.MARRIAGE=df.MARRIAGE.map({2:2,1:1,3:3,0:np.nan})\n",
        "df['EDUCATION']=df.EDUCATION.map({1:1,2:2,3:3,4:4,0:np.nan,5:np.nan,6:np.nan})\n",
        "# df.isnull().sum()\n",
        "\n",
        "## Marriage\n",
        "df1 = df[np.isfinite(df['MARRIAGE'])]\n",
        "df2=df[df['MARRIAGE'].isnull()==True]\n",
        "y1=df1.MARRIAGE\n",
        "df1=df1.drop('MARRIAGE',axis=1)\n",
        "df2=df2.drop('MARRIAGE',axis=1)\n",
        "df1=df1[['AGE','SEX','PAY_0','PAY_2','PAY_3']]\n",
        "df2=df2[['AGE','SEX','PAY_0','PAY_2','PAY_3']]\n",
        "clf = LogisticRegression(max_iter = 10000)\n",
        "clf.fit(df1,y1)\n",
        "y_pred=clf.predict(df2)\n",
        "df2['MARRIAGE']=y_pred\n",
        "df1['MARRIAGE']=y1\n",
        "df1=df1[['MARRIAGE']]\n",
        "df2=df2[['MARRIAGE']]\n",
        "B=pd.concat([df1,df2])\n",
        "B.sort_index(inplace=True)\n",
        "df.MARRIAGE=B"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yCZVXnwH_SmM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Education\n",
        "df1 = df[np.isfinite(df['EDUCATION'])]\n",
        "df2=df[df['EDUCATION'].isnull()==True]\n",
        "y1=df1.EDUCATION\n",
        "df1=df1.drop('EDUCATION',axis=1)\n",
        "df2=df2.drop('EDUCATION',axis=1)\n",
        "df1=df1[['AGE','SEX','MARRIAGE','PAY_0','PAY_2','PAY_3','PAY_4','PAY_5']]\n",
        "df2=df2[['AGE','SEX','MARRIAGE','PAY_0','PAY_2','PAY_3','PAY_4','PAY_5']]\n",
        "clf = LogisticRegression(max_iter = 10000)\n",
        "clf.fit(df1,y1)\n",
        "y_pred=clf.predict(df2)\n",
        "df2['EDUCATION']=y_pred\n",
        "df1['EDUCATION']=y1\n",
        "df1=df1[['EDUCATION']]\n",
        "df2=df2[['EDUCATION']]\n",
        "B=pd.concat([df1,df2])\n",
        "B.sort_index(inplace=True)\n",
        "df.EDUCATION=B"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3TXfgpdc_dh-",
        "colab_type": "code",
        "outputId": "e6e110fc-8138-431c-ce4a-6a3f3abe5590",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        }
      },
      "source": [
        "df.describe()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>LIMIT_BAL</th>\n",
              "      <th>SEX</th>\n",
              "      <th>EDUCATION</th>\n",
              "      <th>MARRIAGE</th>\n",
              "      <th>AGE</th>\n",
              "      <th>PAY_0</th>\n",
              "      <th>PAY_2</th>\n",
              "      <th>PAY_3</th>\n",
              "      <th>PAY_4</th>\n",
              "      <th>PAY_5</th>\n",
              "      <th>PAY_6</th>\n",
              "      <th>BILL_AMT1</th>\n",
              "      <th>BILL_AMT2</th>\n",
              "      <th>BILL_AMT3</th>\n",
              "      <th>BILL_AMT4</th>\n",
              "      <th>BILL_AMT5</th>\n",
              "      <th>BILL_AMT6</th>\n",
              "      <th>PAY_AMT1</th>\n",
              "      <th>PAY_AMT2</th>\n",
              "      <th>PAY_AMT3</th>\n",
              "      <th>PAY_AMT4</th>\n",
              "      <th>PAY_AMT5</th>\n",
              "      <th>PAY_AMT6</th>\n",
              "      <th>default</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>30000.000000</td>\n",
              "      <td>30000.000000</td>\n",
              "      <td>30000.000000</td>\n",
              "      <td>30000.000000</td>\n",
              "      <td>30000.000000</td>\n",
              "      <td>30000.000000</td>\n",
              "      <td>30000.000000</td>\n",
              "      <td>30000.000000</td>\n",
              "      <td>30000.000000</td>\n",
              "      <td>30000.000000</td>\n",
              "      <td>30000.000000</td>\n",
              "      <td>30000.000000</td>\n",
              "      <td>30000.000000</td>\n",
              "      <td>30000.000000</td>\n",
              "      <td>3.000000e+04</td>\n",
              "      <td>30000.000000</td>\n",
              "      <td>30000.000000</td>\n",
              "      <td>30000.000000</td>\n",
              "      <td>30000.000000</td>\n",
              "      <td>3.000000e+04</td>\n",
              "      <td>30000.00000</td>\n",
              "      <td>30000.000000</td>\n",
              "      <td>30000.000000</td>\n",
              "      <td>30000.000000</td>\n",
              "      <td>30000.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>15000.500000</td>\n",
              "      <td>167484.322667</td>\n",
              "      <td>1.603733</td>\n",
              "      <td>1.817000</td>\n",
              "      <td>1.554500</td>\n",
              "      <td>35.485500</td>\n",
              "      <td>-0.016700</td>\n",
              "      <td>-0.133767</td>\n",
              "      <td>-0.166200</td>\n",
              "      <td>-0.220667</td>\n",
              "      <td>-0.266200</td>\n",
              "      <td>-0.291100</td>\n",
              "      <td>51223.330900</td>\n",
              "      <td>49179.075167</td>\n",
              "      <td>4.701315e+04</td>\n",
              "      <td>43262.948967</td>\n",
              "      <td>40311.400967</td>\n",
              "      <td>38871.760400</td>\n",
              "      <td>5663.580500</td>\n",
              "      <td>5.921163e+03</td>\n",
              "      <td>5225.68150</td>\n",
              "      <td>4826.076867</td>\n",
              "      <td>4799.387633</td>\n",
              "      <td>5215.502567</td>\n",
              "      <td>0.221200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>8660.398374</td>\n",
              "      <td>129747.661567</td>\n",
              "      <td>0.489129</td>\n",
              "      <td>0.708892</td>\n",
              "      <td>0.518239</td>\n",
              "      <td>9.217904</td>\n",
              "      <td>1.123802</td>\n",
              "      <td>1.197186</td>\n",
              "      <td>1.196868</td>\n",
              "      <td>1.169139</td>\n",
              "      <td>1.133187</td>\n",
              "      <td>1.149988</td>\n",
              "      <td>73635.860576</td>\n",
              "      <td>71173.768783</td>\n",
              "      <td>6.934939e+04</td>\n",
              "      <td>64332.856134</td>\n",
              "      <td>60797.155770</td>\n",
              "      <td>59554.107537</td>\n",
              "      <td>16563.280354</td>\n",
              "      <td>2.304087e+04</td>\n",
              "      <td>17606.96147</td>\n",
              "      <td>15666.159744</td>\n",
              "      <td>15278.305679</td>\n",
              "      <td>17777.465775</td>\n",
              "      <td>0.415062</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>10000.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>-2.000000</td>\n",
              "      <td>-2.000000</td>\n",
              "      <td>-2.000000</td>\n",
              "      <td>-2.000000</td>\n",
              "      <td>-2.000000</td>\n",
              "      <td>-2.000000</td>\n",
              "      <td>-165580.000000</td>\n",
              "      <td>-69777.000000</td>\n",
              "      <td>-1.572640e+05</td>\n",
              "      <td>-170000.000000</td>\n",
              "      <td>-81334.000000</td>\n",
              "      <td>-339603.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>7500.750000</td>\n",
              "      <td>50000.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>28.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>3558.750000</td>\n",
              "      <td>2984.750000</td>\n",
              "      <td>2.666250e+03</td>\n",
              "      <td>2326.750000</td>\n",
              "      <td>1763.000000</td>\n",
              "      <td>1256.000000</td>\n",
              "      <td>1000.000000</td>\n",
              "      <td>8.330000e+02</td>\n",
              "      <td>390.00000</td>\n",
              "      <td>296.000000</td>\n",
              "      <td>252.500000</td>\n",
              "      <td>117.750000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>15000.500000</td>\n",
              "      <td>140000.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>34.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>22381.500000</td>\n",
              "      <td>21200.000000</td>\n",
              "      <td>2.008850e+04</td>\n",
              "      <td>19052.000000</td>\n",
              "      <td>18104.500000</td>\n",
              "      <td>17071.000000</td>\n",
              "      <td>2100.000000</td>\n",
              "      <td>2.009000e+03</td>\n",
              "      <td>1800.00000</td>\n",
              "      <td>1500.000000</td>\n",
              "      <td>1500.000000</td>\n",
              "      <td>1500.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>22500.250000</td>\n",
              "      <td>240000.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>41.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>67091.000000</td>\n",
              "      <td>64006.250000</td>\n",
              "      <td>6.016475e+04</td>\n",
              "      <td>54506.000000</td>\n",
              "      <td>50190.500000</td>\n",
              "      <td>49198.250000</td>\n",
              "      <td>5006.000000</td>\n",
              "      <td>5.000000e+03</td>\n",
              "      <td>4505.00000</td>\n",
              "      <td>4013.250000</td>\n",
              "      <td>4031.500000</td>\n",
              "      <td>4000.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>30000.000000</td>\n",
              "      <td>1000000.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>79.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>964511.000000</td>\n",
              "      <td>983931.000000</td>\n",
              "      <td>1.664089e+06</td>\n",
              "      <td>891586.000000</td>\n",
              "      <td>927171.000000</td>\n",
              "      <td>961664.000000</td>\n",
              "      <td>873552.000000</td>\n",
              "      <td>1.684259e+06</td>\n",
              "      <td>896040.00000</td>\n",
              "      <td>621000.000000</td>\n",
              "      <td>426529.000000</td>\n",
              "      <td>528666.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 ID       LIMIT_BAL  ...       PAY_AMT6       default\n",
              "count  30000.000000    30000.000000  ...   30000.000000  30000.000000\n",
              "mean   15000.500000   167484.322667  ...    5215.502567      0.221200\n",
              "std     8660.398374   129747.661567  ...   17777.465775      0.415062\n",
              "min        1.000000    10000.000000  ...       0.000000      0.000000\n",
              "25%     7500.750000    50000.000000  ...     117.750000      0.000000\n",
              "50%    15000.500000   140000.000000  ...    1500.000000      0.000000\n",
              "75%    22500.250000   240000.000000  ...    4000.000000      0.000000\n",
              "max    30000.000000  1000000.000000  ...  528666.000000      1.000000\n",
              "\n",
              "[8 rows x 25 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QkuRJqJCBm0s",
        "colab_type": "code",
        "outputId": "72ee0062-c550-4f0f-9a0d-76d31fb72bfc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "# df.drop(['Encode1', 'Encode2', 'LogPay'],axis=1,inplace=True)\n",
        "df.drop('ID',axis=1,inplace=True)\n",
        "\n",
        "# df['PayBill1']=df['BILL_AMT1']*df['PAY_0']\n",
        "# df['PayBill2']=df['BILL_AMT2']*df['PAY_2']\n",
        "# df['PayBill3']=df['BILL_AMT3']*df['PAY_3']\n",
        "# df['PayBill4']=df['BILL_AMT4']*df['PAY_4']\n",
        "# df['PayBill5']=df['BILL_AMT5']*df['PAY_5']\n",
        "# df['PayBill6']=df['BILL_AMT6']*df['PAY_6']\n",
        "\n",
        "# df['PayPay1']=df['PAY_AMT1']*df['PAY_0']\n",
        "# df['PayPay2']=df['PAY_AMT2']*df['PAY_2']\n",
        "# df['PayPay3']=df['PAY_AMT3']*df['PAY_3']\n",
        "# df['PayPay4']=df['PAY_AMT4']*df['PAY_4']\n",
        "# df['PayPay5']=df['PAY_AMT5']*df['PAY_5']\n",
        "# df['PayPay6']=df['PAY_AMT6']*df['PAY_6']\n",
        "\n",
        "df.SEX=df.SEX.map({1:'male',2:'female'})\n",
        "df.EDUCATION=df.EDUCATION.map({1:'graduate school',2:'University',3:'High School',4:'Others'})\n",
        "df.MARRIAGE=df.MARRIAGE.map({1:'married',2:'single',3:'others'})\n",
        "\n",
        "def encode_onehot(df, cols):\n",
        "    vec = DictVectorizer()\n",
        "    vec_data = pd.DataFrame(vec.fit_transform(df[cols].to_dict('records')).toarray())\n",
        "    vec_data.columns = vec.get_feature_names()\n",
        "    vec_data.index = df.index\n",
        "    \n",
        "    df = df.drop(cols, axis=1)\n",
        "    df = df.join(vec_data)\n",
        "    return df\n",
        "X = encode_onehot(df, cols=['SEX'])\n",
        "X1 =encode_onehot(X, cols=['EDUCATION'])\n",
        "X2 =encode_onehot(X1, cols=['MARRIAGE'])\n",
        "X2.columns"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['LIMIT_BAL', 'AGE', 'PAY_0', 'PAY_2', 'PAY_3', 'PAY_4', 'PAY_5',\n",
              "       'PAY_6', 'BILL_AMT1', 'BILL_AMT2', 'BILL_AMT3', 'BILL_AMT4',\n",
              "       'BILL_AMT5', 'BILL_AMT6', 'PAY_AMT1', 'PAY_AMT2', 'PAY_AMT3',\n",
              "       'PAY_AMT4', 'PAY_AMT5', 'PAY_AMT6', 'default', 'SEX=female', 'SEX=male',\n",
              "       'EDUCATION=High School', 'EDUCATION=Others', 'EDUCATION=University',\n",
              "       'EDUCATION=graduate school', 'MARRIAGE=married', 'MARRIAGE=others',\n",
              "       'MARRIAGE=single'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JCOuxYOoG8eS",
        "colab_type": "code",
        "outputId": "ab7d795f-6af0-4ca4-8b64-c39c928817b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "X2.keys()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['LIMIT_BAL', 'AGE', 'PAY_0', 'PAY_2', 'PAY_3', 'PAY_4', 'PAY_5',\n",
              "       'PAY_6', 'BILL_AMT1', 'BILL_AMT2', 'BILL_AMT3', 'BILL_AMT4',\n",
              "       'BILL_AMT5', 'BILL_AMT6', 'PAY_AMT1', 'PAY_AMT2', 'PAY_AMT3',\n",
              "       'PAY_AMT4', 'PAY_AMT5', 'PAY_AMT6', 'default', 'SEX=female', 'SEX=male',\n",
              "       'EDUCATION=High School', 'EDUCATION=Others', 'EDUCATION=University',\n",
              "       'EDUCATION=graduate school', 'MARRIAGE=married', 'MARRIAGE=others',\n",
              "       'MARRIAGE=single'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CS6wZY-SLDdY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# X = df.iloc[:,1:].values\n",
        "# y = df.iloc[:,0].values\n",
        "# X = StandardScaler().fit_transform(X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PeYiXTadLyWf",
        "colab_type": "code",
        "outputId": "0d82ab46-5b14-452d-c5cb-bbd6a26cc62c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "# X = df.iloc[:,1:-1].values\n",
        "# y = df.iloc[:,-1].values\n",
        "# X = df.iloc[:,1:].values\n",
        "# y = df.iloc[:,0].values\n",
        "X1 = X2.drop(['default'],axis=1)\n",
        "X1[['SEX=female','SEX=male',\n",
        "       'EDUCATION=High School', 'EDUCATION=Others', 'EDUCATION=University',\n",
        "       'EDUCATION=graduate school', 'MARRIAGE=married', 'MARRIAGE=others',\n",
        "       'MARRIAGE=single']].replace(0,-1,inplace=True)\n",
        "X1 = X1.values\n",
        "y = df.default.values\n",
        "# X=X1.copy()\n",
        "X = StandardScaler().fit_transform(X1)\n",
        "# y=y[:100];X=X[:100,:]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py:4172: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  method=method,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i3ii9l83SFns",
        "colab_type": "code",
        "outputId": "a22c410f-1114-483e-a184-020d0fc27bc3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "X2.columns"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['LIMIT_BAL', 'AGE', 'PAY_0', 'PAY_2', 'PAY_3', 'PAY_4', 'PAY_5',\n",
              "       'PAY_6', 'BILL_AMT1', 'BILL_AMT2', 'BILL_AMT3', 'BILL_AMT4',\n",
              "       'BILL_AMT5', 'BILL_AMT6', 'PAY_AMT1', 'PAY_AMT2', 'PAY_AMT3',\n",
              "       'PAY_AMT4', 'PAY_AMT5', 'PAY_AMT6', 'default', 'SEX=female', 'SEX=male',\n",
              "       'EDUCATION=High School', 'EDUCATION=Others', 'EDUCATION=University',\n",
              "       'EDUCATION=graduate school', 'MARRIAGE=married', 'MARRIAGE=others',\n",
              "       'MARRIAGE=single'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_MioSU3Mr_lR",
        "colab_type": "code",
        "outputId": "25b866a0-4f3b-4da3-ae3d-2b97c6d6886d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "X.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(30000, 29)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "wSvKRSRMKXjN"
      },
      "source": [
        "## Setting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IbeBjCIys_Yf",
        "colab": {}
      },
      "source": [
        "def newset(y, Z, T):\n",
        "  y = y.reshape((-1, 1))\n",
        "  new_y = torch.tensor(np.concatenate((y, Z), axis=1)).float()\n",
        "  new_data = torch.tensor(T).float()\n",
        "  return new_y, new_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Vq7KQ9o0wFM6",
        "colab": {}
      },
      "source": [
        "# Nrun,split_size,sigma,n,p,p1,alpha,verbose, n_splits=50,0.2,1,70000,31,1,0.05,0,2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c-bp1aF90t_5",
        "colab_type": "text"
      },
      "source": [
        "## MLP (Baseline)\n",
        "No attack pure MLP baseline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RlinqJPV0zMZ",
        "colab_type": "code",
        "outputId": "4c5c78ea-852b-44ce-995c-b82efec6f30c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        }
      },
      "source": [
        "max_epoch = 50\n",
        "lr = 1e-4 #5e-6 for german\n",
        "D_in, H1, D_out = X.shape[1], 200, 1 #p1_new will be selected by lasso later\n",
        "# print(D_in, D_out)\n",
        "batch_size = 512\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
        "X_train, X_test = torch.tensor(X_train).float(), torch.tensor(X_test).float()\n",
        "y_train, y_test = torch.tensor(y_train).reshape((-1,1)).float(), \\\n",
        "torch.tensor(y_test).reshape((-1,1)).float()\n",
        "\n",
        "Train_dataset = TensorDataset(X_train, y_train)\n",
        "trainloader = DataLoader(dataset=Train_dataset, batch_size=batch_size, shuffle=True)\n",
        "Test_dataset = TensorDataset(X_test, y_test)\n",
        "testloader = DataLoader(dataset=Test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "torch.manual_seed(0)\n",
        "\n",
        "MLP = nn.Sequential(\n",
        "    nn.Linear(D_in, H1),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(H1, H1),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(H1, D_out),\n",
        "    # nn.Sigmoid()\n",
        ")\n",
        "\n",
        "optimizer = torch.optim.Adam(MLP.parameters(), lr=lr)\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "old_val_error=1e12\n",
        "patience=0\n",
        "\n",
        "for epoch in range(max_epoch):\n",
        "    for batch_X, batch_y in trainloader:\n",
        "        optimizer.zero_grad()\n",
        "        batch_y_pred = MLP(batch_X)\n",
        "        batch_loss = criterion(batch_y_pred, batch_y)\n",
        "        batch_loss.backward()\n",
        "        optimizer.step()\n",
        "    with torch.no_grad(): \n",
        "      # for batch_T_test, batch_yZ_test in testloader:\n",
        "      val_y_test = MLP(X_test)\n",
        "      val_loss = criterion(val_y_test, y_test)\n",
        "      val_acc = np.mean((val_y_test.cpu().detach().numpy()>0)==y_test.numpy())\n",
        "      print(epoch+1, 'val loss', val_loss, 'val accuracy', val_acc)\n",
        "    #early stopping\n",
        "      if val_loss.item()<old_val_error:\n",
        "          old_val_error=val_loss.item()\n",
        "          patience=0\n",
        "      else:\n",
        "          patience+=1  \n",
        "      if patience == 2:\n",
        "          print('break at epoch', epoch)\n",
        "          break"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 val loss tensor(0.5548) val accuracy 0.7838333333333334\n",
            "2 val loss tensor(0.5137) val accuracy 0.7838333333333334\n",
            "3 val loss tensor(0.4940) val accuracy 0.8003333333333333\n",
            "4 val loss tensor(0.4808) val accuracy 0.807\n",
            "5 val loss tensor(0.4710) val accuracy 0.8103333333333333\n",
            "6 val loss tensor(0.4634) val accuracy 0.8138333333333333\n",
            "7 val loss tensor(0.4580) val accuracy 0.816\n",
            "8 val loss tensor(0.4531) val accuracy 0.8148333333333333\n",
            "9 val loss tensor(0.4503) val accuracy 0.8183333333333334\n",
            "10 val loss tensor(0.4476) val accuracy 0.8153333333333334\n",
            "11 val loss tensor(0.4455) val accuracy 0.817\n",
            "12 val loss tensor(0.4437) val accuracy 0.82\n",
            "13 val loss tensor(0.4425) val accuracy 0.8163333333333334\n",
            "14 val loss tensor(0.4409) val accuracy 0.8198333333333333\n",
            "15 val loss tensor(0.4402) val accuracy 0.8215\n",
            "16 val loss tensor(0.4388) val accuracy 0.8208333333333333\n",
            "17 val loss tensor(0.4376) val accuracy 0.8203333333333334\n",
            "18 val loss tensor(0.4364) val accuracy 0.8205\n",
            "19 val loss tensor(0.4356) val accuracy 0.8205\n",
            "20 val loss tensor(0.4347) val accuracy 0.8215\n",
            "21 val loss tensor(0.4340) val accuracy 0.8205\n",
            "22 val loss tensor(0.4337) val accuracy 0.822\n",
            "23 val loss tensor(0.4326) val accuracy 0.822\n",
            "24 val loss tensor(0.4319) val accuracy 0.8221666666666667\n",
            "25 val loss tensor(0.4317) val accuracy 0.8216666666666667\n",
            "26 val loss tensor(0.4314) val accuracy 0.8205\n",
            "27 val loss tensor(0.4309) val accuracy 0.8228333333333333\n",
            "28 val loss tensor(0.4308) val accuracy 0.8226666666666667\n",
            "29 val loss tensor(0.4300) val accuracy 0.8231666666666667\n",
            "30 val loss tensor(0.4298) val accuracy 0.8228333333333333\n",
            "31 val loss tensor(0.4293) val accuracy 0.823\n",
            "32 val loss tensor(0.4291) val accuracy 0.8233333333333334\n",
            "33 val loss tensor(0.4290) val accuracy 0.8236666666666667\n",
            "34 val loss tensor(0.4288) val accuracy 0.8235\n",
            "35 val loss tensor(0.4291) val accuracy 0.8235\n",
            "36 val loss tensor(0.4280) val accuracy 0.8223333333333334\n",
            "37 val loss tensor(0.4281) val accuracy 0.8228333333333333\n",
            "38 val loss tensor(0.4282) val accuracy 0.8236666666666667\n",
            "break at epoch 37\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "SWyLRZXsVoUb"
      },
      "source": [
        "## DPLM\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "otSJSBcnOodg",
        "colab_type": "text"
      },
      "source": [
        "No attack pure MLP baseline, OLS,DebiNet (forward-backward, Lasso, Elastic Net, two-level SLOPE, adaptive lasso) attack MLP with different number of layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gPHHBVYsib2w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def PLM(X_train, X_test, y_train, y_test, coef):\n",
        "  new_p1 = sum(coef!=0)\n",
        "  Z_train = X_train[:, coef!=0]\n",
        "  T_train = X_train[:, coef==0]\n",
        "  Z_test = X_test[:, coef!=0]\n",
        "  T_test = X_test[:, coef==0]\n",
        "  #LASSO+PLM\n",
        "  yZ_train, T_train = newset(y_train, Z_train, T_train)\n",
        "  yZ_test, T_test = newset(y_test, Z_test, T_test)\n",
        "  # print(yZ_train.shape, T_train.shape)\n",
        "\n",
        "  max_epoch = 1000\n",
        "  lr = 1e-4\n",
        "  D_in, H, D_out = X.shape[1]-new_p1, 500, new_p1+1 #p1_new will be selected by lasso later\n",
        "  # print(D_in, D_out)\n",
        "  batch_size = 1024\n",
        "\n",
        "  Train_dataset = TensorDataset(T_train, yZ_train)\n",
        "  trainloader = DataLoader(dataset=Train_dataset, batch_size=batch_size, shuffle=True)\n",
        "  Test_dataset = TensorDataset(T_test, yZ_test)\n",
        "  testloader = DataLoader(dataset=Test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "  model = nn.Sequential(\n",
        "      nn.Linear(D_in, H),\n",
        "      nn.ReLU(),\n",
        "      nn.Linear(H, D_out),\n",
        "  )\n",
        "\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr=lr,weight_decay=2)\n",
        "  criterion = nn.MSELoss()\n",
        "  old_val_error=1e12\n",
        "  patience=0\n",
        "\n",
        "  for epoch in range(max_epoch):\n",
        "    for batch_T, batch_yZ in trainloader:\n",
        "      optimizer.zero_grad()\n",
        "      batch_yZ_pred = model(batch_T)\n",
        "      batch_loss = criterion(batch_yZ_pred, batch_yZ)\n",
        "\n",
        "      batch_loss.backward()\n",
        "      optimizer.step()\n",
        "    with torch.no_grad(): \n",
        "      val_yZ_test = model(T_test)\n",
        "      val_loss = criterion(val_yZ_test, yZ_test)\n",
        "      val_acc = np.mean((val_yZ_test.cpu().detach().numpy()>0)==yZ_test.numpy())\n",
        "      # print(epoch+1, 'val loss', val_loss, 'val accuracy', val_acc)\n",
        "      if val_loss.item()<old_val_error:\n",
        "          old_val_error=val_loss.item()\n",
        "          patience=0\n",
        "      else:\n",
        "          patience+=1  \n",
        "      if patience == 2:\n",
        "          break\n",
        "  print('training with', epoch, 'steps')\n",
        "  whole_pred=model(T_train).detach().numpy()\n",
        "  mean_conditional_y=whole_pred[:,0]\n",
        "  mean_conditional_Z=whole_pred[:,1:]\n",
        "  whole_pred_te=model(T_test).detach().numpy()\n",
        "  mean_conditional_y_te=whole_pred_te[:,0]\n",
        "  mean_conditional_Z_te=whole_pred_te[:,1:]\n",
        "  PLM_ols = LinearRegression(fit_intercept = False).fit(Z_train-mean_conditional_Z, y_train.reshape(-1,1)-mean_conditional_y.reshape(-1,1))\n",
        "  temp=coef.copy()\n",
        "  temp[coef!=0]=PLM_ols.coef_[0]\n",
        "\n",
        "  return temp"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LYgHPCWyNZAD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def simulations(X, y, split_size=0.2, lasso_alpha=2, elas_alpha=1, l1_ratio=0.5, verbose=0):\n",
        "  beta_ols, beta_plm_lasso, beta_plm_elas, beta_plm_lars=[],[],[],[]\n",
        "  torch.manual_seed(0)\n",
        "  np.random.seed(0)\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=split_size, random_state=42)\n",
        "\n",
        "  # LASSO\n",
        "  lasso = Lasso(alpha = lasso_alpha, fit_intercept=False) # lasso: alpha=1 prediction bad; alpha=0.1 no zero; mixture 0.15\n",
        "  lasso.fit(X_train, y_train)\n",
        "  lasso_coef=lasso.coef_\n",
        "  print('LASSO selects ',sum(lasso_coef!=0),' variables out of ', X.shape[1])\n",
        "\n",
        "\n",
        "  # Elastic Net\n",
        "  elas = ElasticNet(alpha = elas_alpha, l1_ratio=l1_ratio, fit_intercept=False)\n",
        "  elas.fit(X_train, y_train)\n",
        "  elas_coef=elas.coef_\n",
        "  print('Elastic net selects ',sum(elas_coef!=0),' variables out of ', X.shape[1])\n",
        "\n",
        "\n",
        "  # Lars\n",
        "  lars = Lars(n_nonzero_coefs=10, fit_intercept=False) # , \n",
        "  lars.fit(X_train, y_train)\n",
        "  lars_coef=lars.coef_\n",
        "  print('Lars selects ',sum(lars_coef!=0),' variables out of ', X.shape[1])\n",
        "\n",
        "\n",
        "  # OLS if low dimension\n",
        "  ols = LinearRegression(fit_intercept=False).fit(X_train, y_train)\n",
        "  beta_ols.append(ols.coef_)\n",
        "  # y_ols.append(ols.predict(X_train))\n",
        "  # y_ols_te.append(ols.predict(X_test))\n",
        "  # print(MSE(ols.predict(X_test),y_test.flatten()))\n",
        "  print('acc of ols', np.mean(abs(ols.predict(X_test)-y_test.flatten())<0.5))\n",
        "\n",
        "  temp_lasso = PLM(X_train, X_test, y_train, y_test, lasso_coef)\n",
        "  beta_plm_lasso.append(temp_lasso)\n",
        "\n",
        "  temp_elas = PLM(X_train, X_test, y_train, y_test, elas_coef)\n",
        "  beta_plm_elas.append(temp_elas)\n",
        "\n",
        "  temp_lars = PLM(X_train, X_test, y_train, y_test, lars_coef)\n",
        "  beta_plm_lars.append(temp_lars)\n",
        "  # y_plm.append(mean_conditional_y.flatten()+(Z_train-mean_conditional_Z).dot((PLM_ols.coef_).reshape(-1)))\n",
        "  # y_plm_te.append(mean_conditional_y_te.flatten()+(Z_test-mean_conditional_Z_te).dot((PLM_ols.coef_).reshape(-1)))\n",
        "\n",
        "\n",
        "  # if verbose==1:\n",
        "  #   #Output\n",
        "  #   print('LASSO selects ',sum(lasso_coef!=0),' variables out of ', X.shape[1])\n",
        "  #   print('Lasso: ', lasso_coef[lasso_coef!=0]) #lasso\n",
        "  #   print('DebiNet: ', PLM_ols.coef_)# lasso+PLM\n",
        "\n",
        "  return ([beta_ols, beta_plm_lasso, beta_plm_elas, beta_plm_lars,[lasso_coef],[elas_coef]])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IHFBZWizlK5t",
        "colab_type": "text"
      },
      "source": [
        "## Attack & Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9QlZ9JizmFNk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def attack(result, mode):\n",
        "  print('MLP(Baseline)')\n",
        "  MLP.eval()\n",
        "  val_y_test = MLP(X_test)\n",
        "  val_loss = criterion(val_y_test, y_test)\n",
        "  print('val loss', val_loss)\n",
        "  print('accuracy',np.mean((val_y_test.cpu().detach().numpy()>0)==y_test.numpy()))\n",
        "  print('AUC',roc_auc_score(y_test.numpy(),val_y_test.cpu().detach().numpy()))\n",
        "  for i in range(len(result)):\n",
        "    print('--------------------------------')\n",
        "    print('PLM with variable selection method: ', mode[i])\n",
        "    col_to_attack=np.argmax(np.abs(result[i]))\n",
        "    print(col_to_attack, result[i][0].flatten()[col_to_attack])\n",
        "    Xtest=X_test.cpu().detach().numpy()\n",
        "    temp_min, temp_max = min(Xtest[:, col_to_attack]), max(Xtest[:, col_to_attack])\n",
        "    # print(temp_min,temp_max)\n",
        "    new_X_test = Xtest.copy()\n",
        "    if result[i][0].flatten()[col_to_attack]>0:\n",
        "      # print('Sign of coeficient: pos')\n",
        "      new_X_test[y_test.numpy().flatten()==1,col_to_attack]=temp_min\n",
        "      new_X_test[y_test.numpy().flatten()==0,col_to_attack]=temp_max\n",
        "    else:\n",
        "      # print('Sign of coeficient: neg')\n",
        "      new_X_test[y_test.numpy().flatten()==1,col_to_attack]=temp_max\n",
        "      new_X_test[y_test.numpy().flatten()==0,col_to_attack]=temp_min\n",
        "    # print('Average difference:', np.mean(new_X_test-Xtest))\n",
        "\n",
        "    val_y_test = MLP(torch.tensor(new_X_test))\n",
        "    val_loss = criterion(val_y_test, y_test)\n",
        "    print('val loss', val_loss)\n",
        "    print('accuracy',np.mean((val_y_test.cpu().detach().numpy()>0)==y_test.numpy()))\n",
        "    print('AUC',roc_auc_score(y_test.numpy(),val_y_test.cpu().detach().numpy()>0))\n",
        "    print('Recall',recall_score(y_test.numpy(),val_y_test.cpu().detach().numpy()>0))\n",
        "    print('F1 score',f1_score(y_test.numpy(),val_y_test.cpu().detach().numpy()>0))\n",
        "    print('Precision',precision_score(y_test.numpy(),val_y_test.cpu().detach().numpy()>0))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OFEqzSj-YrzU",
        "colab_type": "code",
        "outputId": "90036762-1ea9-4284-aa7f-b7890dd65541",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "result = simulations(X, y, lasso_alpha=0.01,elas_alpha=0.02) # 0.02\n",
        "attack(result, mode = ['ols', 'lasso_PLM', 'elastic_PLM', 'Lars_PLM','Lasso','Elastic'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LASSO selects  9  variables out of  29\n",
            "Elastic net selects  11  variables out of  29\n",
            "Lars selects  10  variables out of  29\n",
            "Low dimension\n",
            "acc of ols 0.781\n",
            "training with 22 steps\n",
            "training with 21 steps\n",
            "training with 20 steps\n",
            "MLP(Baseline)\n",
            "val loss tensor(0.4282, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "accuracy 0.8236666666666667\n",
            "AUC 0.771828903646043\n",
            "--------------------------------\n",
            "PLM with variable selection method:  ols\n",
            "24 604014430879.992\n",
            "val loss tensor(0.3946, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "accuracy 0.8395\n",
            "AUC 0.6865509818287217\n",
            "Recall 0.4171164225134927\n",
            "F1 score 0.5290953545232274\n",
            "Precision 0.42768447136336835\n",
            "Precision 0.7232620320855615\n",
            "--------------------------------\n",
            "PLM with variable selection method:  lasso_PLM\n",
            "2 0.1027046915131916\n",
            "val loss tensor(3.9474, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "accuracy 0.007666666666666666\n",
            "AUC 0.01605809117066471\n",
            "Recall 0.03084040092521203\n",
            "F1 score 0.01325820351342393\n",
            "Precision 0.209760421371545\n",
            "Precision 0.008444162972345366\n",
            "--------------------------------\n",
            "PLM with variable selection method:  elastic_PLM\n",
            "2 0.1081905304566122\n",
            "val loss tensor(3.9474, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "accuracy 0.007666666666666666\n",
            "AUC 0.01605809117066471\n",
            "Recall 0.03084040092521203\n",
            "F1 score 0.01325820351342393\n",
            "Precision 0.209760421371545\n",
            "Precision 0.008444162972345366\n",
            "--------------------------------\n",
            "PLM with variable selection method:  Lars_PLM\n",
            "2 0.10866154936075824\n",
            "val loss tensor(3.9474, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "accuracy 0.007666666666666666\n",
            "AUC 0.01605809117066471\n",
            "Recall 0.03084040092521203\n",
            "F1 score 0.01325820351342393\n",
            "Precision 0.209760421371545\n",
            "Precision 0.008444162972345366\n",
            "--------------------------------\n",
            "PLM with variable selection method:  Lasso\n",
            "2 0.10268362799949034\n",
            "val loss tensor(3.9474, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "accuracy 0.007666666666666666\n",
            "AUC 0.01605809117066471\n",
            "Recall 0.03084040092521203\n",
            "F1 score 0.01325820351342393\n",
            "Precision 0.209760421371545\n",
            "Precision 0.008444162972345366\n",
            "--------------------------------\n",
            "PLM with variable selection method:  Elastic\n",
            "2 0.10099773641879639\n",
            "val loss tensor(3.9474, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "accuracy 0.007666666666666666\n",
            "AUC 0.01605809117066471\n",
            "Recall 0.03084040092521203\n",
            "F1 score 0.01325820351342393\n",
            "Precision 0.209760421371545\n",
            "Precision 0.008444162972345366\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "elQTailB33pC",
        "colab_type": "code",
        "outputId": "1390431e-8254-426b-a80b-21478f654564",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "result[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([-1.13262653e-02,  1.17909768e-02,  1.06420580e-01,  2.65700866e-02,\n",
              "         1.10613842e-02,  7.99071966e-03,  2.98622695e-03,  3.39648096e-03,\n",
              "        -4.63214105e-02,  1.31788624e-02,  2.61750924e-03, -1.20683291e-02,\n",
              "        -1.36021313e-03,  8.95980366e-03, -9.94911410e-03, -4.54067424e-03,\n",
              "         1.78350626e-03, -2.82208869e-03, -2.95587609e-03, -3.10972902e-03,\n",
              "         1.01865460e+09,  1.01865460e+09,  4.48026288e+11,  7.72797185e+10,\n",
              "         6.04014431e+11,  5.78854747e+11,  5.22589118e+10,  1.08279943e+10,\n",
              "         5.23458161e+10])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 656
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0bnL6A4gAKw_",
        "colab_type": "code",
        "outputId": "88f62048-00fd-4482-d033-aab08171d2d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "result[4]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([-0.00888635,  0.00361456,  0.10268363,  0.02423038,  0.00880484,\n",
              "         0.00610534,  0.        ,  0.        , -0.02475438, -0.        ,\n",
              "        -0.        , -0.        , -0.        , -0.        , -0.00340103,\n",
              "        -0.        , -0.        , -0.        , -0.        , -0.        ,\n",
              "        -0.        ,  0.        ,  0.        , -0.        , -0.        ,\n",
              "         0.        ,  0.        ,  0.        , -0.0052299 ])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 657
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iBOwqs2PANQ6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}